#!/usr/bin/env python3
"""
WebRTC åŸŸåæ‰«æå™¨
ä» Tranco Top 1M åŸŸååˆ—è¡¨ä¸­è¯»å–åŸŸåï¼Œè®¿é—®ä¸»é¡µå†…å®¹ï¼Œä½¿ç”¨ AI æ¨¡å‹åˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡
"""

import os
import sys
import csv
import json
import time
import argparse
import requests
from typing import Optional, Dict, List
from datetime import datetime
import signal

# OpenRouter API é…ç½®
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")

# é»˜è®¤é…ç½®
DEFAULT_MODEL = "openai/gpt-4o-mini"  # ä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹
DEFAULT_TIMEOUT = 10  # HTTP è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
DEFAULT_MAX_CONTENT_LENGTH = 50000  # æœ€å¤§é¡µé¢å†…å®¹é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰
DEFAULT_DELAY = 1  # è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰

# ç»“æœæ–‡ä»¶
RESULTS_FILE = "webrtc_scan_results.json"
PROGRESS_FILE = "webrtc_scan_progress.json"

# å…¨å±€å˜é‡ç”¨äºä¼˜é›…é€€å‡º
interrupted = False


def signal_handler(sig, frame):
    """å¤„ç† Ctrl+C ä¿¡å·ï¼Œä¼˜é›…é€€å‡º"""
    global interrupted
    print("\n[!] æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦...")
    interrupted = True


signal.signal(signal.SIGINT, signal_handler)


def read_domains(csv_file: str, start_line: Optional[int] = None, max_domains: Optional[int] = None) -> List[Dict]:
    """
    ä» CSV æ–‡ä»¶è¯»å–åŸŸååˆ—è¡¨
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        start_line: ä»ç¬¬å‡ è¡Œå¼€å§‹è¯»å–ï¼ˆ1-basedï¼‰
        max_domains: æœ€å¤šè¯»å–å¤šå°‘ä¸ªåŸŸå
        
    Returns:
        åŸŸååˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« rank å’Œ domain
    """
    domains = []
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        for line_num, row in enumerate(reader, start=1):
            if start_line and line_num < start_line:
                continue
            if len(row) >= 2:
                rank = row[0].strip()
                domain = row[1].strip()
                if domain:
                    domains.append({
                        "rank": rank,
                        "domain": domain
                    })
                    if max_domains and len(domains) >= max_domains:
                        break
    return domains


def fetch_homepage(domain: str) -> Optional[Dict]:
    """
    è·å–åŸŸåä¸»é¡µå†…å®¹
    
    Args:
        domain: åŸŸå
        
    Returns:
        åŒ…å«é¡µé¢å†…å®¹çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    urls = [
        f"https://{domain}",
        f"http://{domain}"
    ]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
    }
    
    for url in urls:
        try:
            response = requests.get(
                url,
                headers=headers,
                timeout=DEFAULT_TIMEOUT,
                allow_redirects=True,
                verify=False  # å¿½ç•¥ SSL è¯ä¹¦éªŒè¯
            )
            
            # æ£€æŸ¥çŠ¶æ€ç 
            if response.status_code == 200:
                content = response.text
                
                # é™åˆ¶å†…å®¹é•¿åº¦
                if len(content) > DEFAULT_MAX_CONTENT_LENGTH:
                    content = content[:DEFAULT_MAX_CONTENT_LENGTH] + "\n[å†…å®¹å·²æˆªæ–­...]"
                
                return {
                    "url": url,
                    "status_code": response.status_code,
                    "content": content,
                    "content_length": len(response.text),
                    "content_type": response.headers.get("Content-Type", ""),
                    "title": extract_title(content)
                }
        except requests.exceptions.SSLError:
            # SSL é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
        except requests.exceptions.Timeout:
            # è¶…æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
        except requests.exceptions.RequestException as e:
            # å…¶ä»–è¯·æ±‚é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
    
    return None


def extract_title(content: str) -> str:
    """ä» HTML å†…å®¹ä¸­æå–æ ‡é¢˜"""
    import re
    # å°è¯•æå– <title> æ ‡ç­¾
    title_match = re.search(r'<title[^>]*>([^<]+)</title>', content, re.IGNORECASE)
    if title_match:
        return title_match.group(1).strip()
    
    # å°è¯•æå– <h1> æ ‡ç­¾
    h1_match = re.search(r'<h1[^>]*>([^<]+)</h1>', content, re.IGNORECASE)
    if h1_match:
        return h1_match.group(1).strip()
    
    return ""


def analyze_webrtc_with_ai(domain: str, page_content: Dict) -> Optional[Dict]:
    """
    ä½¿ç”¨ AI æ¨¡å‹åˆ†æé¡µé¢å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡
    
    Args:
        domain: åŸŸå
        page_content: é¡µé¢å†…å®¹å­—å…¸
        
    Returns:
        AI åˆ†æç»“æœï¼ŒåŒ…å«åˆ¤æ–­å’ŒåŸå› 
    """
    if not OPENROUTER_API_KEY:
        print("[!] é”™è¯¯: æœªè®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        return None
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""è¯·åˆ†æä»¥ä¸‹ç½‘ç«™å†…å®¹ï¼Œåˆ¤æ–­è¯¥åŸŸåæ˜¯å¦å¯èƒ½æä¾› WebRTC ç›¸å…³çš„æœåŠ¡ã€‚

åŸŸå: {domain}
URL: {page_content['url']}
çŠ¶æ€ç : {page_content['status_code']}
å†…å®¹ç±»å‹: {page_content['content_type']}
æ ‡é¢˜: {page_content['title']}

é¡µé¢å†…å®¹:
{page_content['content']}

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æ:
1. é¡µé¢æ–‡æœ¬ä¸­æ˜¯å¦æåˆ° WebRTCã€STUNã€TURNã€ICEã€RTCPeerConnection ç­‰ç›¸å…³æŠ€æœ¯
2. é¡µé¢æ˜¯å¦æ¶‰åŠè§†é¢‘ä¼šè®®ã€å®æ—¶é€šä¿¡ã€è¯­éŸ³é€šè¯ã€å±å¹•å…±äº«ç­‰åŠŸèƒ½
3. æ˜¯å¦æœ‰ç›¸å…³çš„ JavaScript åº“å¼•ç”¨ï¼ˆå¦‚ SimpleWebRTCã€PeerJSã€Socket.io ç­‰ï¼‰
4. é¡µé¢çš„ä¸šåŠ¡ç±»å‹æ˜¯å¦å¯èƒ½ä½¿ç”¨ WebRTC æŠ€æœ¯

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœ:
{{
    "has_webrtc": true/false,
    "confidence": "high/medium/low",
    "reasons": ["åŸå› 1", "åŸå› 2", ...],
    "keywords_found": ["å…³é”®è¯1", "å…³é”®è¯2", ...]
}}"""

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://github.com/turn-client",
        "X-Title": "WebRTC Domain Scanner"
    }
    
    payload = {
        "model": DEFAULT_MODEL,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "stream": True,
        "temperature": 0.3
    }
    
    try:
        response = requests.post(
            OPENROUTER_API_URL,
            headers=headers,
            json=payload,
            stream=True,
            timeout=60
        )
        
        # æ£€æŸ¥åˆå§‹çŠ¶æ€ç 
        if response.status_code != 200:
            error_data = response.json()
            print(f"[!] API é”™è¯¯: {error_data.get('error', {}).get('message', 'Unknown error')}")
            return None
        
        # å¤„ç†æµå¼å“åº”
        buffer = ""
        full_content = ""
        
        for chunk in response.iter_content(chunk_size=1024, decode_unicode=True):
            if interrupted:
                break
                
            buffer += chunk
            
            while True:
                # æŸ¥æ‰¾å®Œæ•´çš„ SSE è¡Œ
                line_end = buffer.find('\n')
                if line_end == -1:
                    break
                
                line = buffer[:line_end].strip()
                buffer = buffer[line_end + 1:]
                
                if line.startswith('data: '):
                    data = line[6:]
                    if data == '[DONE]':
                        break
                    
                    try:
                        data_obj = json.loads(data)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                        if 'error' in data_obj:
                            print(f"[!] æµå¼å“åº”é”™è¯¯: {data_obj['error'].get('message', 'Unknown error')}")
                            return None
                        
                        # æå–å†…å®¹
                        delta = data_obj.get('choices', [{}])[0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content += content
                            print(content, end='', flush=True)
                            
                        # æ£€æŸ¥ finish_reason
                        finish_reason = data_obj.get('choices', [{}])[0].get('finish_reason')
                        if finish_reason == 'error':
                            print("\n[!] æµå¼å“åº”å› é”™è¯¯ç»ˆæ­¢")
                            return None
                            
                    except json.JSONDecodeError:
                        pass
        
        print()  # æ¢è¡Œ
        
        # å°è¯•ä»å®Œæ•´å†…å®¹ä¸­æå– JSON
        try:
            # æŸ¥æ‰¾ JSON å¯¹è±¡
            json_start = full_content.find('{')
            json_end = full_content.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                json_str = full_content[json_start:json_end]
                result = json.loads(json_str)
                return result
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œè¿”å›åŸå§‹å†…å®¹
                return {
                    "has_webrtc": None,
                    "confidence": "unknown",
                    "reasons": ["æ— æ³•è§£æ AI å“åº”"],
                    "raw_response": full_content
                }
        except json.JSONDecodeError:
            return {
                "has_webrtc": None,
                "confidence": "unknown",
                "reasons": ["AI å“åº”æ ¼å¼é”™è¯¯"],
                "raw_response": full_content
            }
            
    except requests.exceptions.RequestException as e:
        print(f"[!] API è¯·æ±‚å¤±è´¥: {e}")
        return None


def save_progress(current_line: int, results: List[Dict]):
    """ä¿å­˜è¿›åº¦å’Œç»“æœ"""
    progress = {
        "last_line": current_line,
        "timestamp": datetime.now().isoformat(),
        "total_processed": len(results)
    }
    
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(progress, f, indent=2, ensure_ascii=False)
    
    with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)


def load_progress() -> int:
    """åŠ è½½ä¸Šæ¬¡çš„è¿›åº¦"""
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            progress = json.load(f)
            return progress.get("last_line", 1)
    return 1


def main():
    parser = argparse.ArgumentParser(
        description="æ‰«æåŸŸååˆ—è¡¨ï¼Œä½¿ç”¨ AI åˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡"
    )
    parser.add_argument(
        "--csv",
        default="tranco_top_1m_domains/top-1m.csv",
        help="CSV æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: tranco_top_1m_domains/top-1m.csvï¼‰"
    )
    parser.add_argument(
        "--start",
        type=int,
        help="ä»ç¬¬å‡ è¡Œå¼€å§‹ï¼ˆ1-basedï¼‰"
    )
    parser.add_argument(
        "--max",
        type=int,
        help="æœ€å¤šå¤„ç†å¤šå°‘ä¸ªåŸŸå"
    )
    parser.add_argument(
        "--model",
        default=DEFAULT_MODEL,
        help=f"OpenRouter æ¨¡å‹åç§°ï¼ˆé»˜è®¤: {DEFAULT_MODEL}ï¼‰"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=DEFAULT_DELAY,
        help=f"è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤: {DEFAULT_DELAY}ï¼‰"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="ä»ä¸Šæ¬¡åœæ­¢çš„ä½ç½®ç»§ç»­"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ¨¡å‹
    global DEFAULT_MODEL
    if args.model:
        DEFAULT_MODEL = args.model
    
    # æ£€æŸ¥ API Key
    if not OPENROUTER_API_KEY:
        print("[!] é”™è¯¯: è¯·è®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        print("    export OPENROUTER_API_KEY='your-api-key'")
        sys.exit(1)
    
    # ç¡®å®šèµ·å§‹è¡Œ
    start_line = args.start
    if args.resume and not start_line:
        start_line = load_progress()
        if start_line > 1:
            print(f"[+] ä»ä¸Šæ¬¡åœæ­¢çš„ä½ç½®ç»§ç»­: ç¬¬ {start_line} è¡Œ")
    
    # è¯»å–åŸŸååˆ—è¡¨
    print(f"[+] è¯»å–åŸŸååˆ—è¡¨: {args.csv}")
    domains = read_domains(args.csv, start_line=start_line, max_domains=args.max)
    
    if not domains:
        print("[!] æ²¡æœ‰æ‰¾åˆ°åŸŸå")
        return
    
    print(f"[+] æ‰¾åˆ° {len(domains)} ä¸ªåŸŸåå¾…å¤„ç†")
    
    # åŠ è½½å·²æœ‰ç»“æœ
    results = []
    if os.path.exists(RESULTS_FILE):
        with open(RESULTS_FILE, 'r', encoding='utf-8') as f:
            results = json.load(f)
    
    # å¤„ç†æ¯ä¸ªåŸŸå
    for i, domain_info in enumerate(domains, start=1):
        if interrupted:
            print("\n[!] å·²ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦...")
            break
        
        rank = domain_info["rank"]
        domain = domain_info["domain"]
        current_line = (start_line or 1) + i - 1
        
        print(f"\n[{i}/{len(domains)}] å¤„ç†åŸŸå: {domain} (æ’å: {rank}, è¡Œå·: {current_line})")
        
        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
        already_processed = any(
            r.get("rank") == rank and r.get("domain") == domain
            for r in results
        )
        
        if already_processed:
            print(f"[*] å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
            continue
        
        # è·å–ä¸»é¡µå†…å®¹
        print(f"[*] è·å–ä¸»é¡µå†…å®¹...")
        page_content = fetch_homepage(domain)
        
        if not page_content:
            print(f"[!] æ— æ³•è·å–ä¸»é¡µå†…å®¹")
            result = {
                "rank": rank,
                "domain": domain,
                "line": current_line,
                "timestamp": datetime.now().isoformat(),
                "status": "failed",
                "error": "æ— æ³•è·å–ä¸»é¡µå†…å®¹"
            }
            results.append(result)
            save_progress(current_line, results)
            time.sleep(args.delay)
            continue
        
        print(f"[+] æˆåŠŸè·å–ä¸»é¡µå†…å®¹ ({page_content['content_length']} å­—ç¬¦)")
        print(f"    URL: {page_content['url']}")
        print(f"    æ ‡é¢˜: {page_content['title']}")
        
        # ä½¿ç”¨ AI åˆ†æ
        print(f"[*] ä½¿ç”¨ AI åˆ†æ WebRTC æœåŠ¡...")
        ai_result = analyze_webrtc_with_ai(domain, page_content)
        
        if ai_result:
            has_webrtc = ai_result.get("has_webrtc", None)
            confidence = ai_result.get("confidence", "unknown")
            reasons = ai_result.get("reasons", [])
            keywords = ai_result.get("keywords_found", [])
            
            print(f"[+] AI åˆ†æç»“æœ:")
            print(f"    åŒ…å« WebRTC: {has_webrtc}")
            print(f"    ç½®ä¿¡åº¦: {confidence}")
            if reasons:
                print(f"    åŸå› : {', '.join(reasons[:3])}")
            
            result = {
                "rank": rank,
                "domain": domain,
                "line": current_line,
                "timestamp": datetime.now().isoformat(),
                "status": "success",
                "page_info": {
                    "url": page_content["url"],
                    "status_code": page_content["status_code"],
                    "content_type": page_content["content_type"],
                    "title": page_content["title"],
                    "content_length": page_content["content_length"]
                },
                "ai_analysis": {
                    "has_webrtc": has_webrtc,
                    "confidence": confidence,
                    "reasons": reasons,
                    "keywords_found": keywords
                }
            }
        else:
            print(f"[!] AI åˆ†æå¤±è´¥")
            result = {
                "rank": rank,
                "domain": domain,
                "line": current_line,
                "timestamp": datetime.now().isoformat(),
                "status": "ai_failed",
                "page_info": {
                    "url": page_content["url"],
                    "status_code": page_content["status_code"],
                    "content_type": page_content["content_type"],
                    "title": page_content["title"],
                    "content_length": page_content["content_length"]
                },
                "error": "AI åˆ†æå¤±è´¥"
            }
        
        results.append(result)
        save_progress(current_line, results)
        
        # å»¶è¿Ÿ
        if i < len(domains):
            time.sleep(args.delay)
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    save_progress(start_line + len(domains) if start_line else len(domains), results)
    
    # ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š æ‰«æå®Œæˆç»Ÿè®¡")
    print("="*60)
    total = len(results)
    success = sum(1 for r in results if r.get("status") == "success")
    failed = sum(1 for r in results if r.get("status") == "failed")
    ai_failed = sum(1 for r in results if r.get("status") == "ai_failed")
    has_webrtc = sum(1 for r in results 
                    if r.get("status") == "success" 
                    and r.get("ai_analysis", {}).get("has_webrtc") is True)
    
    print(f"æ€»è®¡: {total}")
    print(f"æˆåŠŸ: {success}")
    print(f"å¤±è´¥: {failed}")
    print(f"AI åˆ†æå¤±è´¥: {ai_failed}")
    print(f"åŒ…å« WebRTC: {has_webrtc}")
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {RESULTS_FILE}")


if __name__ == "__main__":
    # ç¦ç”¨ SSL è­¦å‘Š
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    main()

