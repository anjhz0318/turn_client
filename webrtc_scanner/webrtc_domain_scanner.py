#!/usr/bin/env python3
"""
WebRTC åŸŸåæ‰«æå™¨
ä» Tranco Top 1M åŸŸååˆ—è¡¨ä¸­è¯»å–åŸŸåï¼Œè®¿é—®ä¸»é¡µå†…å®¹ï¼Œä½¿ç”¨ AI æ¨¡å‹åˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡
"""

import os
import sys
import csv
import json
import time
import argparse
import requests
from typing import Optional, Dict, List
from datetime import datetime
import signal
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

# å¯¼å…¥é…ç½®æ–‡ä»¶
from domain_scanner_config import (
    OPENROUTER_API_URL,
    OPENROUTER_API_KEY,
    get_api_key,
    DEFAULT_MODEL,
    DEFAULT_TIMEOUT,
    DEFAULT_MAX_CONTENT_LENGTH,
    DEFAULT_DELAY,
    DEFAULT_CSV_FILE,
    REQUEST_HEADERS,
    AI_TEMPERATURE,
    AI_STREAM_TIMEOUT,
    RESULTS_FILE_PREFIX,
    RESULTS_FILE_SUFFIX,
    PROGRESS_FILE,
    BATCH_SIZE,
    validate_config
)

# å¯¼å…¥é¡µé¢å…ƒç´ æå–å™¨
from page_element_extractor import (
    fetch_and_extract_elements,
    format_elements_for_ai
)

# å…¨å±€å˜é‡ç”¨äºä¼˜é›…é€€å‡º
interrupted = False

# å…¨å±€é”ç”¨äºæ–‡ä»¶è¯»å†™ä¿æŠ¤
file_lock = threading.Lock()
results_lock = threading.Lock()  # ç”¨äºä¿æŠ¤ results åˆ—è¡¨


def signal_handler(sig, frame):
    """å¤„ç† Ctrl+C ä¿¡å·ï¼Œä¼˜é›…é€€å‡º"""
    global interrupted
    print("\n[!] æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦...")
    interrupted = True
    # ç¡®ä¿ä¿å­˜å½“å‰è¿›åº¦
    try:
        results = load_results()
        if results:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå¤„ç†çš„åŸŸåè¡Œå·
            last_line = max((r.get("line", 0) for r in results), default=1)
            save_progress(last_line, results)
            print(f"[+] è¿›åº¦å·²ä¿å­˜ï¼Œæœ€åå¤„ç†çš„è¡Œå·: {last_line}")
    except Exception as e:
        print(f"[!] ä¿å­˜è¿›åº¦æ—¶å‡ºé”™: {e}")


signal.signal(signal.SIGINT, signal_handler)


def read_domains(csv_file: str, start_line: Optional[int] = None, max_domains: Optional[int] = None) -> List[Dict]:
    """
    ä» CSV æ–‡ä»¶è¯»å–åŸŸååˆ—è¡¨
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        start_line: ä»ç¬¬å‡ è¡Œå¼€å§‹è¯»å–ï¼ˆ1-basedï¼‰
        max_domains: æœ€å¤šè¯»å–å¤šå°‘ä¸ªåŸŸå
        
    Returns:
        åŸŸååˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« rankã€domain å’Œ lineï¼ˆå®é™…è¡Œå·ï¼‰
    """
    domains = []
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        for line_num, row in enumerate(reader, start=1):
            if start_line and line_num < start_line:
                continue
            if len(row) >= 2:
                rank = row[0].strip()
                domain = row[1].strip()
                if domain:
                    domains.append({
                        "rank": rank,
                        "domain": domain,
                        "line": line_num  # è®°å½•å®é™…è¡Œå·
                    })
                    if max_domains and len(domains) >= max_domains:
                        break
    return domains


def fetch_homepage(domain: str) -> Optional[Dict]:
    """
    è·å–åŸŸåä¸»é¡µå†…å®¹
    
    Args:
        domain: åŸŸå
        
    Returns:
        åŒ…å«é¡µé¢å†…å®¹çš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å› None
    """
    urls = [
        f"https://{domain}",
        f"http://{domain}"
    ]
    
    for url in urls:
        try:
            response = requests.get(
                url,
                headers=REQUEST_HEADERS,
                timeout=DEFAULT_TIMEOUT,
                allow_redirects=True,
                verify=False  # å¿½ç•¥ SSL è¯ä¹¦éªŒè¯
            )
            
            # æ£€æŸ¥çŠ¶æ€ç 
            if response.status_code == 200:
                # æ­£ç¡®æ£€æµ‹å’Œè®¾ç½®ç¼–ç 
                if response.encoding is None or response.encoding == 'ISO-8859-1':
                    # å°è¯•ä» Content-Type å¤´è·å–ç¼–ç 
                    content_type = response.headers.get("Content-Type", "")
                    if 'charset=' in content_type:
                        try:
                            charset = content_type.split('charset=')[1].split(';')[0].strip().strip('"\'')
                            response.encoding = charset
                        except:
                            pass
                    
                    # å¦‚æœè¿˜æ˜¯æ— æ³•ç¡®å®šï¼Œå°è¯•å¸¸è§ç¼–ç 
                    if response.encoding is None or response.encoding == 'ISO-8859-1':
                        # å°è¯•æ£€æµ‹ç¼–ç 
                        try:
                            import chardet
                            detected = chardet.detect(response.content)
                            if detected and detected.get('encoding'):
                                response.encoding = detected['encoding']
                            else:
                                response.encoding = 'utf-8'
                        except ImportError:
                            # chardet æœªå®‰è£…ï¼Œé»˜è®¤ä½¿ç”¨ UTF-8
                            response.encoding = 'utf-8'
                
                # è·å–æ–‡æœ¬å†…å®¹ï¼Œç¡®ä¿æ˜¯ UTF-8
                try:
                    content = response.text
                    # å¦‚æœæ–‡æœ¬åŒ…å«æ— æ³•è§£ç çš„å­—ç¬¦ï¼Œå°è¯•é‡æ–°ç¼–ç 
                    if not isinstance(content, str):
                        content = str(content, encoding='utf-8', errors='replace')
                except UnicodeDecodeError:
                    # å¦‚æœè§£ç å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ errors='replace' æˆ– errors='ignore'
                    content = response.content.decode('utf-8', errors='replace')
                except Exception:
                    # æœ€åå°è¯•ï¼šå…ˆè§£ç ä¸ºå­—èŠ‚ï¼Œå†å°è¯•å¸¸è§ç¼–ç 
                    try:
                        content = response.content.decode('utf-8', errors='replace')
                    except:
                        content = response.content.decode('latin-1', errors='replace')
                
                # æ¸…ç†å†…å®¹ï¼šç§»é™¤æ§åˆ¶å­—ç¬¦ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦
                import re
                content = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f-\x9f]', '', content)
                
                # é™åˆ¶å†…å®¹é•¿åº¦
                original_length = len(content)
                if len(content) > DEFAULT_MAX_CONTENT_LENGTH:
                    content = content[:DEFAULT_MAX_CONTENT_LENGTH] + "\n[å†…å®¹å·²æˆªæ–­...]"
                
                # è·å–å“åº”ä½“å‰50ä¸ªå­—ç¬¦ï¼Œç”¨äºæ£€æŸ¥ç¼–ç é—®é¢˜
                content_preview = content[:50] if content else ""
                
                return {
                    "url": url,
                    "status_code": response.status_code,
                    "content": content,
                    "content_length": original_length,
                    "content_type": response.headers.get("Content-Type", ""),
                    "title": extract_title(content),
                    "content_preview": content_preview  # å“åº”ä½“å‰50ä¸ªå­—ç¬¦ï¼Œç”¨äºæ£€æŸ¥ç¼–ç 
                }
        except requests.exceptions.SSLError:
            # SSL é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
        except requests.exceptions.Timeout:
            # è¶…æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
        except requests.exceptions.RequestException as e:
            # å…¶ä»–è¯·æ±‚é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª URL
            continue
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼ˆå¯èƒ½æ˜¯ç¼–ç é—®é¢˜ï¼‰
            print(f"[!] å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
            continue
    
    return None


def extract_title(content: str) -> str:
    """ä» HTML å†…å®¹ä¸­æå–æ ‡é¢˜"""
    import re
    import html
    
    # å°è¯•æå– <title> æ ‡ç­¾
    title_match = re.search(r'<title[^>]*>([^<]+)</title>', content, re.IGNORECASE)
    if title_match:
        title = title_match.group(1).strip()
        # è§£ç  HTML å®ä½“ï¼ˆå¦‚ &amp; ç­‰ï¼‰
        try:
            title = html.unescape(title)
        except:
            pass
        return title
    
    # å°è¯•æå– <h1> æ ‡ç­¾
    h1_match = re.search(r'<h1[^>]*>([^<]+)</h1>', content, re.IGNORECASE)
    if h1_match:
        title = h1_match.group(1).strip()
        # è§£ç  HTML å®ä½“
        try:
            title = html.unescape(title)
        except:
            pass
        return title
    
    return ""


def analyze_webrtc_with_ai(domain: str, elements_data: Dict, api_key: str, model: str) -> Optional[Dict]:
    """
    ä½¿ç”¨ AI æ¨¡å‹åˆ†æé¡µé¢å…ƒç´ ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡
    
    Args:
        domain: åŸŸå
        elements_data: åŒ…å«æå–å…ƒç´ çš„é¡µé¢æ•°æ®å­—å…¸
        api_key: OpenRouter API Key
        model: æ¨¡å‹åç§°
        
    Returns:
        AI åˆ†æç»“æœï¼ŒåŒ…å«åˆ¤æ–­å’ŒåŸå› 
    """
    if not api_key:
        print("[!] é”™è¯¯: æœªè®¾ç½® OPENROUTER_API_KEY")
        return None
    
    # æ ¼å¼åŒ–å…ƒç´ ä¿¡æ¯ç”¨äº AI åˆ†æ
    elements_text = format_elements_for_ai(elements_data)
    elements_text_length = len(elements_text)
    print(f"[*] æå–çš„å…ƒç´ ä¿¡æ¯é•¿åº¦: {elements_text_length} å­—ç¬¦")
    title = elements_data.get('title', '')
    
    # ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²éƒ½æ˜¯æœ‰æ•ˆçš„ UTF-8
    if not isinstance(elements_text, str):
        try:
            elements_text = str(elements_text, encoding='utf-8', errors='replace')
        except:
            elements_text = str(elements_text)
    
    if not isinstance(title, str):
        try:
            title = str(title, encoding='utf-8', errors='replace')
        except:
            title = str(title)
    
    # æ„å»ºæç¤ºè¯
    prompt = f"""
ä½ æ˜¯ä¸€åç²¾é€šå‰ç«¯ä¸å®æ—¶é€šä¿¡æŠ€æœ¯çš„åˆ†æä¸“å®¶ã€‚ç°åœ¨æˆ‘å°†æä¾›ä¸€ä¸ªç½‘ç«™ä¸»é¡µçš„é¡µé¢å…ƒç´ ä¿¡æ¯ï¼ˆåŒ…æ‹¬æŒ‰é’®ã€é“¾æ¥ã€è¾“å…¥æ¡†çš„æ–‡æœ¬å’Œå±æ€§ï¼‰ï¼Œè¯·ä½ åˆ¤æ–­è¯¥ç½‘ç«™æ˜¯å¦ä½¿ç”¨äº† WebRTCï¼ˆWeb Real-Time Communicationï¼‰ æŠ€æœ¯ã€‚
è¯·ä½ ä» ç½‘ç«™ä¸šåŠ¡è¯­ä¹‰ è¿›è¡Œåˆ†æï¼Œå¹¶æŒ‰ä»¥ä¸‹æ­¥éª¤è¾“å‡ºç»“æœã€‚

ä»é¡µé¢çš„æ ‡é¢˜ã€æŒ‰é’®æ–‡æœ¬ã€é“¾æ¥æ–‡æœ¬ã€è¾“å…¥æ¡†çš„ placeholder æˆ– value ç­‰å…ƒç´ ä¸­ï¼Œæ¨æ–­ç½‘ç«™çš„ä¸šåŠ¡ç±»å‹ã€‚
è‹¥ç½‘ç«™åŠŸèƒ½ä¸ä»¥ä¸‹ä»»æ„åœºæ™¯ç›¸å…³ï¼Œåˆ™å¯èƒ½ä½¿ç”¨ WebRTCï¼š

ï¼ˆ1ï¼‰è§†é¢‘é€šä¿¡ç±»åœºæ™¯

è§†é¢‘ä¼šè®®ã€åœ¨çº¿ä¼šè®®å®¤ã€å¤šæ–¹ä¼šè®®ã€è¿œç¨‹ä¼šè®®ã€è§†é¢‘é€šè¯ã€ä¸€å¯¹ä¸€è§†é¢‘èŠå¤©ã€è§†é¢‘é¢è¯•ã€åœ¨çº¿é—®è¯Šã€è¿œç¨‹è¯¾å ‚ã€è™šæ‹Ÿä¼šè®®å¹³å°

ï¼ˆ2ï¼‰è¯­éŸ³ä¸èŠå¤©ç±»åœºæ™¯

å®æ—¶è¯­éŸ³é€šè¯ã€è¯­éŸ³èŠå¤©å®¤ã€è¯­éŸ³æˆ¿é—´ã€è¯­éŸ³åŒ¹é…ã€è¯­éŸ³å®¢æœã€å³æ—¶èŠå¤©ã€å®æ—¶æ²Ÿé€šã€åœ¨çº¿å¯¹è®²

ï¼ˆ3ï¼‰ç¤¾äº¤ä¸äº’åŠ¨ç±»åœºæ™¯

éšæœºè§†é¢‘èŠå¤©ã€åœ¨çº¿è§†é¢‘é…å¯¹ã€å®æ—¶çº¦ä¼šã€é¢å¯¹é¢é€šä¿¡ã€äº’åŠ¨ç¤¾äº¤ã€è§†é¢‘è§é¢

ï¼ˆ4ï¼‰åä½œä¸è¿œç¨‹æ“ä½œç±»åœºæ™¯

å±å¹•å…±äº«ã€è¿œç¨‹åä½œã€åœ¨çº¿æ¼”ç¤ºã€å¤šäººç™½æ¿ã€åœ¨çº¿åŠå…¬ã€è¿œç¨‹æ§åˆ¶ã€åœ¨çº¿è¾…å¯¼

ï¼ˆ5ï¼‰åª’ä½“ä¸ç›´æ’­ç±»åœºæ™¯

å®æ—¶ç›´æ’­ã€ä½å»¶è¿Ÿæ¨æµã€äº’åŠ¨ç›´æ’­ã€è§†é¢‘å®¢æœã€è™šæ‹Ÿå‰å°ã€è¿œç¨‹å±•ç¤ºã€å®æ—¶åª’ä½“æ’­æ”¾

è‹¥é¡µé¢å…ƒç´ ä¸­å‡ºç°è¿™äº›åŠŸèƒ½æè¿°æˆ–æç¤ºæ€§è¯æ±‡ï¼Œå¯åˆ¤å®šè¯¥ç½‘ç«™å…·å¤‡ WebRTC é€šä¿¡èƒ½åŠ›ã€‚

3. è¾“å‡ºæ ¼å¼

ç»¼åˆä¸Šè¿°åˆ†æï¼Œè¾“å‡ºä¸€ä¸ªç»“æ„åŒ– JSONï¼š
{{
  "webrtc_usage": "ç¡®å®šä½¿ç”¨ | å¯èƒ½ä½¿ç”¨ | æœªå‘ç°ä½¿ç”¨",
  "evidence": ["å…³é”®è¯æˆ–APIç‰‡æ®µ1", "ä¸šåŠ¡è¯­ä¹‰çº¿ç´¢2", "æ¥å£è·¯å¾„3"],
  "reasoning": "ç®€è¦è¯´æ˜æ¨ç†è¿‡ç¨‹"
}}


ä»¥ä¸‹æ˜¯ç½‘ç«™é¡µé¢å…ƒç´ ä¿¡æ¯

åŸŸå: {domain}
URL: {elements_data['url']}
çŠ¶æ€ç : {elements_data['status_code']}
å†…å®¹ç±»å‹: {elements_data['content_type']}
æ ‡é¢˜: {title}

é¡µé¢å…ƒç´ ä¿¡æ¯:
{elements_text}

"""
    
    # ç¡®ä¿ prompt æ˜¯æœ‰æ•ˆçš„ UTF-8 å­—ç¬¦ä¸²
    if not isinstance(prompt, str):
        prompt = str(prompt, encoding='utf-8', errors='replace')

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ],
        "stream": False,  # ä½¿ç”¨éæµå¼å“åº”
        "temperature": AI_TEMPERATURE
    }
    
    try:
        response = requests.post(
            OPENROUTER_API_URL,
            headers=headers,
            json=payload,
            timeout=AI_STREAM_TIMEOUT
        )
        
        # æ£€æŸ¥åˆå§‹çŠ¶æ€ç 
        if response.status_code != 200:
            try:
                error_data = response.json()
                error_msg = error_data.get('error', {})
                if isinstance(error_msg, dict):
                    error_msg = error_msg.get('message', str(error_msg))
                print(f"[!] API é”™è¯¯: {error_msg}")
            except:
                print(f"[!] API é”™è¯¯: HTTP {response.status_code}")
                print(f"[!] å“åº”å†…å®¹: {response.text[:500]}")
            return None
        
        # å¤„ç†éæµå¼å“åº”
        try:
            response_data = response.json()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if 'error' in response_data:
                error_msg = response_data['error']
                if isinstance(error_msg, dict):
                    error_msg = error_msg.get('message', str(error_msg))
                print(f"[!] API è¿”å›é”™è¯¯: {error_msg}")
                return None
            
            # æå–å®Œæ•´å“åº”å†…å®¹
            choices = response_data.get('choices', [])
            if not choices:
                print("[!] API å“åº”ä¸­æ²¡æœ‰ choices å­—æ®µ")
                return None
            
            # è·å–ç¬¬ä¸€æ¡æ¶ˆæ¯çš„å®Œæ•´å†…å®¹
            message = choices[0].get('message', {})
            full_content = message.get('content', '')
            
            if not full_content:
                print("[!] API å“åº”ä¸­æ²¡æœ‰å†…å®¹")
                return None
            
            # æ‰“å°å“åº”å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            print(full_content)
            
            # å°è¯•ä»å®Œæ•´å†…å®¹ä¸­æå– JSON
            try:
                # æŸ¥æ‰¾ JSON å¯¹è±¡
                json_start = full_content.find('{')
                json_end = full_content.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_str = full_content[json_start:json_end]
                    result = json.loads(json_str)
                    return result
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° JSONï¼Œè¿”å›åŸå§‹å†…å®¹
                    return {
                        "webrtc_usage": "æœªå‘ç°ä½¿ç”¨",
                        "evidence": [],
                        "reasoning": "æ— æ³•ä»å“åº”ä¸­æå– JSONï¼ŒåŸå§‹å“åº”ï¼š" + full_content[:200]
                    }
            except json.JSONDecodeError as e:
                return {
                    "webrtc_usage": "æœªå‘ç°ä½¿ç”¨",
                    "evidence": [],
                    "reasoning": f"AI å“åº”æ ¼å¼é”™è¯¯: {str(e)}",
                    "raw_response": full_content[:500]
                }
                
        except json.JSONDecodeError as e:
            print(f"[!] æ— æ³•è§£æ JSON å“åº”: {e}")
            print(f"[!] å“åº”å†…å®¹: {response.text[:500]}")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"[!] API è¯·æ±‚å¤±è´¥: {e}")
        return None


def get_results_file_path(batch_number: int) -> str:
    """
    æ ¹æ®æ‰¹æ¬¡å·ç”Ÿæˆç»“æœæ–‡ä»¶è·¯å¾„
    
    Args:
        batch_number: æ‰¹æ¬¡å·ï¼ˆä»1å¼€å§‹ï¼‰
        
    Returns:
        ç»“æœæ–‡ä»¶è·¯å¾„
    """
    return f"{RESULTS_FILE_PREFIX}_{batch_number:04d}{RESULTS_FILE_SUFFIX}"


def save_progress(current_line: int, results: List[Dict]):
    """
    ä¿å­˜è¿›åº¦å’Œç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    æ¯1000ä¸ªåŸŸåä¿å­˜åˆ°ä¸€ä¸ªæ–‡ä»¶
    
    Args:
        current_line: å½“å‰å¤„ç†çš„è¡Œå·ï¼ˆç”¨äºå…¼å®¹ï¼Œå®é™…ä¼šä» results ä¸­è®¡ç®—æœ€å¤§è¡Œå·ï¼‰
        results: æ‰€æœ‰ç»“æœåˆ—è¡¨
    """
    with file_lock:
        # è®¡ç®—å½“å‰æ‰¹æ¬¡å·ï¼ˆä»1å¼€å§‹ï¼‰
        total_processed = len(results)
        current_batch = (total_processed - 1) // BATCH_SIZE + 1
        
        # ä»ç»“æœä¸­è®¡ç®—å®é™…çš„æœ€å¤§è¡Œå·
        if results:
            actual_last_line = max((r.get("line", 0) for r in results), default=current_line)
        else:
            actual_last_line = current_line
        
        # ä¿å­˜è¿›åº¦ä¿¡æ¯
        progress = {
            "last_line": actual_last_line,  # ä½¿ç”¨å®é™…çš„æœ€å¤§è¡Œå·
            "timestamp": datetime.now().isoformat(),
            "total_processed": total_processed,
            "current_batch": current_batch,
            "current_batch_size": total_processed % BATCH_SIZE if total_processed % BATCH_SIZE != 0 else BATCH_SIZE
        }
        
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress, f, indent=2, ensure_ascii=False)
        
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»“æœ
        batch_start = (current_batch - 1) * BATCH_SIZE
        batch_end = min(batch_start + BATCH_SIZE, total_processed)
        current_batch_results = results[batch_start:batch_end]
        
        # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„ç»“æœ
        current_batch_file = get_results_file_path(current_batch)
        with open(current_batch_file, 'w', encoding='utf-8') as f:
            json.dump(current_batch_results, f, indent=2, ensure_ascii=False)
        
        # å¦‚æœå½“å‰æ‰¹æ¬¡å·²æ»¡ï¼Œæ‰“å°æç¤º
        if len(current_batch_results) == BATCH_SIZE:
            print(f"[+] æ‰¹æ¬¡ {current_batch} å·²æ»¡ï¼ˆ{BATCH_SIZE} ä¸ªåŸŸåï¼‰ï¼Œå·²ä¿å­˜åˆ° {current_batch_file}")


def load_progress() -> int:
    """åŠ è½½ä¸Šæ¬¡çš„è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with file_lock:
        if os.path.exists(PROGRESS_FILE):
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                progress = json.load(f)
                return progress.get("last_line", 1)
    return 1


def load_results(verbose: bool = False) -> List[Dict]:
    """
    åŠ è½½å·²æœ‰ç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    ä»æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶ä¸­åŠ è½½ç»“æœ
    
    Args:
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†çš„åŠ è½½ä¿¡æ¯
    """
    with file_lock:
        results = []
        
        # é¦–å…ˆæ£€æŸ¥è¿›åº¦æ–‡ä»¶ï¼Œè·å–å½“å‰æ‰¹æ¬¡ä¿¡æ¯
        current_batch = 1
        if os.path.exists(PROGRESS_FILE):
            try:
                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                    current_batch = progress.get("current_batch", 1)
            except:
                pass
        
        # å…¼å®¹æ—§æ ¼å¼ï¼šå¦‚æœå­˜åœ¨æ—§çš„å•æ–‡ä»¶æ ¼å¼ï¼Œå…ˆåŠ è½½å®ƒ
        old_results_file = f"{RESULTS_FILE_PREFIX}{RESULTS_FILE_SUFFIX}"
        old_file_loaded = False
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨æ‰¹æ¬¡æ–‡ä»¶
        first_batch_file = get_results_file_path(1)
        has_batch_files = os.path.exists(first_batch_file)
        
        if os.path.exists(old_results_file) and not has_batch_files:
            # åªæœ‰åœ¨æ²¡æœ‰æ‰¹æ¬¡æ–‡ä»¶æ—¶æ‰è½¬æ¢æ—§æ–‡ä»¶
            try:
                with open(old_results_file, 'r', encoding='utf-8') as f:
                    old_results = json.load(f)
                    if old_results:
                        results.extend(old_results)
                        old_file_loaded = True
                        if verbose:
                            print(f"[*] åŠ è½½æ—§æ ¼å¼æ–‡ä»¶: {old_results_file} ({len(old_results)} ä¸ªç»“æœ)")
                        # å°†æ—§æ–‡ä»¶è½¬æ¢ä¸ºæ‰¹æ¬¡æ–‡ä»¶æ ¼å¼
                        if len(old_results) > 0:
                            batch_num = 1
                            for i in range(0, len(old_results), BATCH_SIZE):
                                batch_results = old_results[i:i+BATCH_SIZE]
                                batch_file = get_results_file_path(batch_num)
                                with open(batch_file, 'w', encoding='utf-8') as bf:
                                    json.dump(batch_results, bf, indent=2, ensure_ascii=False)
                                if verbose:
                                    print(f"[*] è½¬æ¢æ—§æ–‡ä»¶åˆ°æ‰¹æ¬¡ {batch_num}: {batch_file} ({len(batch_results)} ä¸ªç»“æœ)")
                                batch_num += 1
                        # å¤‡ä»½æ—§æ–‡ä»¶
                        backup_file = f"{old_results_file}.backup"
                        if not os.path.exists(backup_file):
                            import shutil
                            shutil.copy2(old_results_file, backup_file)
                            if verbose:
                                print(f"[*] æ—§æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")
            except Exception as e:
                if verbose:
                    print(f"[!] åŠ è½½æ—§æ ¼å¼æ–‡ä»¶å¤±è´¥: {e}")
        
        # åŠ è½½æ‰€æœ‰å·²å­˜åœ¨çš„æ‰¹æ¬¡æ–‡ä»¶
        # å¦‚æœå·²ç»ä»æ—§æ–‡ä»¶åŠ è½½äº†ï¼Œè®¡ç®—åº”è¯¥ä»å“ªä¸ªæ‰¹æ¬¡å¼€å§‹åŠ è½½
        start_batch = 1
        if old_file_loaded and results:
            # è®¡ç®—å·²åŠ è½½çš„ç»“æœå¯¹åº”çš„æ‰¹æ¬¡æ•°é‡
            loaded_batches = (len(results) - 1) // BATCH_SIZE + 1
            start_batch = loaded_batches + 1
        
        batch_num = start_batch
        while True:
            batch_file = get_results_file_path(batch_num)
            if os.path.exists(batch_file):
                try:
                    with open(batch_file, 'r', encoding='utf-8') as f:
                        batch_results = json.load(f)
                        results.extend(batch_results)
                        if verbose:
                            print(f"[*] åŠ è½½æ‰¹æ¬¡ {batch_num}: {len(batch_results)} ä¸ªç»“æœ")
                except Exception as e:
                    if verbose:
                        print(f"[!] åŠ è½½æ‰¹æ¬¡æ–‡ä»¶ {batch_file} å¤±è´¥: {e}")
                batch_num += 1
            else:
                break
        
        return results


def process_domain(domain_info: Dict, start_line: int, api_key: str, model: str, delay: float, thread_id: int, num_threads: int) -> Optional[Dict]:
    """
    å¤„ç†å•ä¸ªåŸŸåï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    
    Args:
        domain_info: åŸŸåä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« rankã€domain å’Œ line
        start_line: èµ·å§‹è¡Œå·ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
        api_key: OpenRouter API Key
        model: æ¨¡å‹åç§°
        delay: å»¶è¿Ÿæ—¶é—´
        thread_id: çº¿ç¨‹IDï¼ˆ1-basedï¼‰
        num_threads: çº¿ç¨‹æ€»æ•°
        
    Returns:
        å¤„ç†ç»“æœå­—å…¸ï¼Œå¦‚æœå·²å¤„ç†æˆ–å‡ºé”™åˆ™è¿”å› None
    """
    rank = domain_info["rank"]
    domain = domain_info["domain"]
    actual_line = domain_info.get("line", start_line)  # ä½¿ç”¨å®é™…è¡Œå·
    
    # å°† rank è½¬æ¢ä¸ºæ•´æ•°ç”¨äºçº¿ç¨‹åˆ†é…
    try:
        rank_int = int(rank)
    except (ValueError, TypeError):
        rank_int = hash(rank) % 1000000  # å¦‚æœ rank ä¸æ˜¯æ•°å­—ï¼Œä½¿ç”¨å“ˆå¸Œå€¼
    
    # æ ¹æ® rank % num_threads == thread_id - 1 åˆ¤æ–­æ˜¯å¦ç”±å½“å‰çº¿ç¨‹å¤„ç†
    if rank_int % num_threads != thread_id - 1:
        return None  # ä¸å±äºå½“å‰çº¿ç¨‹å¤„ç†
    
    # åŠ è½½å·²æœ‰ç»“æœå¹¶æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    results = load_results()
    already_processed = any(
        r.get("rank") == rank and r.get("domain") == domain
        for r in results
    )
    
    if already_processed:
        print(f"[çº¿ç¨‹ {thread_id}] åŸŸå {domain} (æ’å: {rank}, è¡Œå·: {actual_line}) å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
        return None
    
    print(f"[çº¿ç¨‹ {thread_id}] å¤„ç†åŸŸå: {domain} (æ’å: {rank}, è¡Œå·: {actual_line})")
    
    # è·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ 
    print(f"[çº¿ç¨‹ {thread_id}] è·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ ...")
    elements_data = fetch_and_extract_elements(domain)
    
    if not elements_data:
        print(f"[çº¿ç¨‹ {thread_id}] æ— æ³•è·å–ä¸»é¡µå†…å®¹")
        result = {
            "rank": rank,
            "domain": domain,
            "line": actual_line,  # ä½¿ç”¨å®é™…è¡Œå·
            "timestamp": datetime.now().isoformat(),
            "status": "failed",
            "error": "æ— æ³•è·å–ä¸»é¡µå†…å®¹",
            "thread_id": thread_id
        }
        
        # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜ç»“æœ
        with results_lock:
            results = load_results()
            results.append(result)
            save_progress(actual_line, results)
        
        time.sleep(delay)
        return result
    
    print(f"[çº¿ç¨‹ {thread_id}] æˆåŠŸè·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ ")
    print(f"[çº¿ç¨‹ {thread_id}] URL: {elements_data['url']}")
    print(f"[çº¿ç¨‹ {thread_id}] æ ‡é¢˜: {elements_data['title']}")
    elements = elements_data.get('elements', {})
    print(f"[çº¿ç¨‹ {thread_id}] æå–çš„å…ƒç´ : {len(elements.get('buttons', []))} ä¸ªæŒ‰é’®, {len(elements.get('links', []))} ä¸ªé“¾æ¥, {len(elements.get('inputs', []))} ä¸ªè¾“å…¥æ¡†")
    
    # ä¸¤é˜¶æ®µ AI åˆ†æï¼šå…ˆç”¨å¿«é€Ÿæ¨¡å‹ï¼Œå¦‚æœå‡ºé”™æˆ–ç»“æœæ˜¯"å¯èƒ½ä½¿ç”¨"åˆ™ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
    print(f"[çº¿ç¨‹ {thread_id}] ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨å¿«é€Ÿæ¨¡å‹ (gemini-2.0-flash-exp) åˆ†æ WebRTC æœåŠ¡...")
    ai_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.0-flash-exp")
    
    # å¦‚æœç¬¬ä¸€æ¬¡åˆ¤æ–­å¤±è´¥ï¼ˆè¿”å› Noneï¼‰ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
    if not ai_result:
        print(f"[çº¿ç¨‹ {thread_id}] ç¬¬ä¸€é˜¶æ®µåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ›´å‡†ç¡®æ¨¡å‹ (gemini-2.5-pro) é‡æ–°å°è¯•...")
        ai_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.5-pro")
        if ai_result:
            print(f"[çº¿ç¨‹ {thread_id}] ä½¿ç”¨æ˜‚è´µæ¨¡å‹åˆ†ææˆåŠŸ")
        else:
            print(f"[çº¿ç¨‹ {thread_id}] æ˜‚è´µæ¨¡å‹åˆ†æä¹Ÿå¤±è´¥")
    # å¦‚æœç¬¬ä¸€æ¬¡åˆ¤æ–­ç»“æœæ˜¯"å¯èƒ½ä½¿ç”¨"ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
    elif ai_result.get("webrtc_usage") == "å¯èƒ½ä½¿ç”¨":
        print(f"[çº¿ç¨‹ {thread_id}] ç¬¬ä¸€é˜¶æ®µç»“æœä¸º'å¯èƒ½ä½¿ç”¨'ï¼Œä½¿ç”¨æ›´å‡†ç¡®æ¨¡å‹ (gemini-2.5-pro) é‡æ–°åˆ¤æ–­...")
        second_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.5-pro")
        if second_result:
            # ä»¥ç¬¬äºŒæ¬¡åˆ¤æ–­çš„ç»“æœä¸ºå‡†
            ai_result = second_result
            print(f"[çº¿ç¨‹ {thread_id}] ç¬¬äºŒé˜¶æ®µåˆ¤æ–­å®Œæˆï¼Œä»¥æœ¬æ¬¡ç»“æœä¸ºå‡†")
        else:
            print(f"[çº¿ç¨‹ {thread_id}] ç¬¬äºŒé˜¶æ®µåˆ¤æ–­å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€é˜¶æ®µç»“æœ")
    
    if ai_result:
        # è§£ææ–°çš„ JSON æ ¼å¼
        webrtc_usage = ai_result.get("webrtc_usage", "æœªå‘ç°ä½¿ç”¨")
        evidence = ai_result.get("evidence", [])
        reasoning = ai_result.get("reasoning", "")
        
        # å°† webrtc_usage è½¬æ¢ä¸ºå¸ƒå°”å€¼
        has_webrtc = webrtc_usage in ["ç¡®å®šä½¿ç”¨", "å¯èƒ½ä½¿ç”¨"]
        
        # æ ¹æ® webrtc_usage ç¡®å®šç½®ä¿¡åº¦
        if webrtc_usage == "ç¡®å®šä½¿ç”¨":
            confidence = "high"
        elif webrtc_usage == "å¯èƒ½ä½¿ç”¨":
            confidence = "medium"
        else:
            confidence = "low"
        
        print(f"[çº¿ç¨‹ {thread_id}] AI åˆ†æç»“æœ:")
        print(f"[çº¿ç¨‹ {thread_id}]   WebRTC ä½¿ç”¨æƒ…å†µ: {webrtc_usage}")
        print(f"[çº¿ç¨‹ {thread_id}]   ç½®ä¿¡åº¦: {confidence}")
        
        result = {
            "rank": rank,
            "domain": domain,
            "line": actual_line,  # ä½¿ç”¨å®é™…è¡Œå·
            "timestamp": datetime.now().isoformat(),
            "status": "success",
            "thread_id": thread_id,
            "page_info": {
                "url": elements_data["url"],
                "status_code": elements_data["status_code"],
                "content_type": elements_data["content_type"],
                "title": elements_data["title"],
                "content_length": elements_data["content_length"],
                "content_preview": elements_data.get("content_preview", "")
            },
            "ai_analysis": {
                "webrtc_usage": webrtc_usage,
                "has_webrtc": has_webrtc,
                "confidence": confidence,
                "evidence": evidence,
                "reasoning": reasoning
            }
        }
    else:
        print(f"[çº¿ç¨‹ {thread_id}] AI åˆ†æå¤±è´¥")
        result = {
            "rank": rank,
            "domain": domain,
            "line": actual_line,  # ä½¿ç”¨å®é™…è¡Œå·
            "timestamp": datetime.now().isoformat(),
            "status": "ai_failed",
            "thread_id": thread_id,
            "page_info": {
                "url": elements_data["url"],
                "status_code": elements_data["status_code"],
                "content_type": elements_data["content_type"],
                "title": elements_data["title"],
                "content_length": elements_data["content_length"],
                "content_preview": elements_data.get("content_preview", "")
            },
            "error": "AI åˆ†æå¤±è´¥"
        }
    
    # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜ç»“æœ
    with results_lock:
        results = load_results()
        results.append(result)
        save_progress(actual_line, results)  # ä½¿ç”¨å®é™…è¡Œå·
    
    # å»¶è¿Ÿ
    time.sleep(delay)
    
    return result


def main():
    # éªŒè¯é…ç½®
    is_valid, error = validate_config()
    if not is_valid:
        print(f"[!] é…ç½®é”™è¯¯: {error}")
        sys.exit(1)
    
    parser = argparse.ArgumentParser(
        description="æ‰«æåŸŸååˆ—è¡¨ï¼Œä½¿ç”¨ AI åˆ¤æ–­æ˜¯å¦åŒ…å« WebRTC ç›¸å…³æœåŠ¡"
    )
    parser.add_argument(
        "--csv",
        default=DEFAULT_CSV_FILE,
        help=f"CSV æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: {DEFAULT_CSV_FILE}ï¼‰"
    )
    parser.add_argument(
        "--start",
        type=int,
        help="ä»ç¬¬å‡ è¡Œå¼€å§‹ï¼ˆ1-basedï¼‰"
    )
    parser.add_argument(
        "--max",
        type=int,
        help="æœ€å¤šå¤„ç†å¤šå°‘ä¸ªåŸŸå"
    )
    parser.add_argument(
        "--model",
        default=DEFAULT_MODEL,
        help=f"OpenRouter æ¨¡å‹åç§°ï¼ˆé»˜è®¤: {DEFAULT_MODEL}ï¼‰"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=DEFAULT_DELAY,
        help=f"è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤: {DEFAULT_DELAY}ï¼‰"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="ä»ä¸Šæ¬¡åœæ­¢çš„ä½ç½®ç»§ç»­"
    )
    parser.add_argument(
        "--threads",
        type=int,
        default=1,
        help="çº¿ç¨‹æ•°é‡ï¼ˆé»˜è®¤: 1ï¼Œå•çº¿ç¨‹æ¨¡å¼ï¼‰"
    )
    
    args = parser.parse_args()
    
    # è·å– API Key
    api_key = get_api_key()
    if not api_key:
        print("[!] é”™è¯¯: è¯·è®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¿®æ”¹é…ç½®æ–‡ä»¶")
        print("    æ–¹å¼1: export OPENROUTER_API_KEY='your-api-key'")
        print("    æ–¹å¼2: ç¼–è¾‘ webrtc_domain_scanner_config.py æ–‡ä»¶")
        sys.exit(1)
    
    # ç¡®å®šèµ·å§‹è¡Œ
    start_line = args.start
    if args.resume and not start_line:
        start_line = load_progress()
        if start_line > 1:
            print(f"[+] ä»ä¸Šæ¬¡åœæ­¢çš„ä½ç½®ç»§ç»­: ç¬¬ {start_line} è¡Œ")
            # åŠ è½½å·²æœ‰ç»“æœå¹¶æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
            existing_results = load_results(verbose=True)
            if existing_results:
                print(f"[+] å·²åŠ è½½ {len(existing_results)} ä¸ªå·²æœ‰ç»“æœ")
    
    # è¯»å–åŸŸååˆ—è¡¨
    print(f"[+] è¯»å–åŸŸååˆ—è¡¨: {args.csv}")
    domains = read_domains(args.csv, start_line=start_line, max_domains=args.max)
    
    if not domains:
        print("[!] æ²¡æœ‰æ‰¾åˆ°åŸŸå")
        return
    
    print(f"[+] æ‰¾åˆ° {len(domains)} ä¸ªåŸŸåå¾…å¤„ç†")
    print(f"[+] ä½¿ç”¨æ¨¡å‹: {args.model}")
    print(f"[+] API Key: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
    print(f"[+] çº¿ç¨‹æ•°é‡: {args.threads}")
    
    # å¤šçº¿ç¨‹å¤„ç†
    if args.threads > 1:
        print(f"[+] ä½¿ç”¨ {args.threads} ä¸ªçº¿ç¨‹å¤„ç†åŸŸå")
        print(f"[+] åˆ†é…è§„åˆ™: ç¬¬ i ä¸ªçº¿ç¨‹å¤„ç† rank % {args.threads} == i-1 çš„åŸŸå")
        
        # å®šä¹‰åŒ…è£…å‡½æ•°ï¼Œæ ¹æ® rank è‡ªåŠ¨åˆ†é…çº¿ç¨‹ID
        def process_domain_wrapper(domain_info: Dict):
            """åŒ…è£…å‡½æ•°ï¼Œæ ¹æ® rank è‡ªåŠ¨è®¡ç®—çº¿ç¨‹ID"""
            rank = domain_info["rank"]
            # è®¡ç®—çº¿ç¨‹IDï¼šrank % num_threads çš„ç»“æœæ˜¯ 0 åˆ° num_threads-1ï¼ŒåŠ 1å¾—åˆ°1-basedçš„çº¿ç¨‹ID
            thread_id = (rank % args.threads) + 1
            return process_domain(
                domain_info,
                start_line or 1,
                api_key,
                args.model,
                args.delay,
                thread_id,
                args.threads
            )
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†
        with ThreadPoolExecutor(max_workers=args.threads) as executor:
            futures = []
            
            for domain_info in domains:
                if interrupted:
                    print("\n[!] å·²ä¸­æ–­ï¼Œç­‰å¾…çº¿ç¨‹å®Œæˆ...")
                    break
                
                # æäº¤ä»»åŠ¡ï¼ˆåŒ…è£…å‡½æ•°ä¼šè‡ªåŠ¨åˆ†é…çº¿ç¨‹IDï¼‰
                future = executor.submit(process_domain_wrapper, domain_info)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            completed = 0
            for future in as_completed(futures):
                if interrupted:
                    print("[!] ä¸­æ–­ä¿¡å·å·²æ¥æ”¶ï¼Œç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...")
                    break
                try:
                    result = future.result()
                    if result:
                        completed += 1
                except Exception as e:
                    print(f"[!] å¤„ç†åŸŸåæ—¶å‡ºé”™: {e}")
            
            # ä¸­æ–­åä¿å­˜æœ€ç»ˆè¿›åº¦
            if interrupted:
                try:
                    results = load_results()
                    if results:
                        last_line = max((r.get("line", 0) for r in results), default=start_line or 1)
                        save_progress(last_line, results)
                        print(f"[+] è¿›åº¦å·²ä¿å­˜ï¼Œæœ€åå¤„ç†çš„è¡Œå·: {last_line}")
                except Exception as e:
                    print(f"[!] ä¿å­˜è¿›åº¦æ—¶å‡ºé”™: {e}")
            
            print(f"[+] çº¿ç¨‹æ± å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {completed} ä¸ªåŸŸå")
    else:
        # å•çº¿ç¨‹å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        print(f"[+] ä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼")
        
        # åŠ è½½å·²æœ‰ç»“æœ
        results = load_results(verbose=(args.resume or start_line is not None))
        
        # å¤„ç†æ¯ä¸ªåŸŸå
        for i, domain_info in enumerate(domains, start=1):
            if interrupted:
                print("\n[!] å·²ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦...")
                # ç¡®ä¿ä¿å­˜å½“å‰è¿›åº¦
                try:
                    if results:
                        last_line = max((r.get("line", 0) for r in results), default=start_line or 1)
                        save_progress(last_line, results)
                        print(f"[+] è¿›åº¦å·²ä¿å­˜ï¼Œæœ€åå¤„ç†çš„è¡Œå·: {last_line}")
                except Exception as e:
                    print(f"[!] ä¿å­˜è¿›åº¦æ—¶å‡ºé”™: {e}")
                break
            
            rank = domain_info["rank"]
            domain = domain_info["domain"]
            current_line = domain_info.get("line", (start_line or 1) + i - 1)  # ä½¿ç”¨å®é™…è¡Œå·
            
            print(f"\n[{i}/{len(domains)}] å¤„ç†åŸŸå: {domain} (æ’å: {rank}, è¡Œå·: {current_line})")
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            already_processed = any(
                r.get("rank") == rank and r.get("domain") == domain
                for r in results
            )
            
            if already_processed:
                print(f"[*] å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
                continue
            
            # è·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ 
            print(f"[*] è·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ ...")
            elements_data = fetch_and_extract_elements(domain)
            
            if not elements_data:
                print(f"[!] æ— æ³•è·å–ä¸»é¡µå†…å®¹")
                result = {
                    "rank": rank,
                    "domain": domain,
                    "line": current_line,
                    "timestamp": datetime.now().isoformat(),
                    "status": "failed",
                    "error": "æ— æ³•è·å–ä¸»é¡µå†…å®¹"
                }
                results.append(result)
                save_progress(current_line, results)
                time.sleep(args.delay)
                continue
            
            print(f"[+] æˆåŠŸè·å–ä¸»é¡µå†…å®¹å¹¶æå–å…ƒç´ ")
            print(f"    URL: {elements_data['url']}")
            print(f"    æ ‡é¢˜: {elements_data['title']}")
            elements = elements_data.get('elements', {})
            print(f"    æå–çš„å…ƒç´ : {len(elements.get('buttons', []))} ä¸ªæŒ‰é’®, {len(elements.get('links', []))} ä¸ªé“¾æ¥, {len(elements.get('inputs', []))} ä¸ªè¾“å…¥æ¡†")
            
            # ä¸¤é˜¶æ®µ AI åˆ†æï¼šå…ˆç”¨å¿«é€Ÿæ¨¡å‹ï¼Œå¦‚æœå‡ºé”™æˆ–ç»“æœæ˜¯"å¯èƒ½ä½¿ç”¨"åˆ™ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
            print(f"[*] ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨å¿«é€Ÿæ¨¡å‹ (gemini-2.0-flash-exp) åˆ†æ WebRTC æœåŠ¡...")
            ai_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.0-flash-exp")
            
            # å¦‚æœç¬¬ä¸€æ¬¡åˆ¤æ–­å¤±è´¥ï¼ˆè¿”å› Noneï¼‰ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
            if not ai_result:
                print(f"[*] ç¬¬ä¸€é˜¶æ®µåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ›´å‡†ç¡®æ¨¡å‹ (gemini-2.5-pro) é‡æ–°å°è¯•...")
                ai_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.5-pro")
                if ai_result:
                    print(f"[+] ä½¿ç”¨æ˜‚è´µæ¨¡å‹åˆ†ææˆåŠŸ")
                else:
                    print(f"[!] æ˜‚è´µæ¨¡å‹åˆ†æä¹Ÿå¤±è´¥")
            # å¦‚æœç¬¬ä¸€æ¬¡åˆ¤æ–­ç»“æœæ˜¯"å¯èƒ½ä½¿ç”¨"ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æ¨¡å‹é‡æ–°åˆ¤æ–­
            elif ai_result.get("webrtc_usage") == "å¯èƒ½ä½¿ç”¨":
                print(f"[*] ç¬¬ä¸€é˜¶æ®µç»“æœä¸º'å¯èƒ½ä½¿ç”¨'ï¼Œä½¿ç”¨æ›´å‡†ç¡®æ¨¡å‹ (gemini-2.5-pro) é‡æ–°åˆ¤æ–­...")
                second_result = analyze_webrtc_with_ai(domain, elements_data, api_key, "gemini-2.5-pro")
                if second_result:
                    # ä»¥ç¬¬äºŒæ¬¡åˆ¤æ–­çš„ç»“æœä¸ºå‡†
                    ai_result = second_result
                    print(f"[+] ç¬¬äºŒé˜¶æ®µåˆ¤æ–­å®Œæˆï¼Œä»¥æœ¬æ¬¡ç»“æœä¸ºå‡†")
                else:
                    print(f"[!] ç¬¬äºŒé˜¶æ®µåˆ¤æ–­å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€é˜¶æ®µç»“æœ")
            
            if ai_result:
                # è§£ææ–°çš„ JSON æ ¼å¼
                webrtc_usage = ai_result.get("webrtc_usage", "æœªå‘ç°ä½¿ç”¨")
                evidence = ai_result.get("evidence", [])
                reasoning = ai_result.get("reasoning", "")
                
                # å°† webrtc_usage è½¬æ¢ä¸ºå¸ƒå°”å€¼
                has_webrtc = webrtc_usage in ["ç¡®å®šä½¿ç”¨", "å¯èƒ½ä½¿ç”¨"]
                
                # æ ¹æ® webrtc_usage ç¡®å®šç½®ä¿¡åº¦
                if webrtc_usage == "ç¡®å®šä½¿ç”¨":
                    confidence = "high"
                elif webrtc_usage == "å¯èƒ½ä½¿ç”¨":
                    confidence = "medium"
                else:
                    confidence = "low"
                
                print(f"[+] AI åˆ†æç»“æœ:")
                print(f"    WebRTC ä½¿ç”¨æƒ…å†µ: {webrtc_usage}")
                print(f"    ç½®ä¿¡åº¦: {confidence}")
                if evidence:
                    print(f"    è¯æ®: {', '.join(evidence[:5])}")
                if reasoning:
                    print(f"    æ¨ç†: {reasoning[:200]}...")
                
                result = {
                    "rank": rank,
                    "domain": domain,
                    "line": current_line,
                    "timestamp": datetime.now().isoformat(),
                    "status": "success",
                    "page_info": {
                        "url": elements_data["url"],
                        "status_code": elements_data["status_code"],
                        "content_type": elements_data["content_type"],
                        "title": elements_data["title"],
                        "content_length": elements_data["content_length"],
                        "content_preview": elements_data.get("content_preview", "")
                    },
                    "ai_analysis": {
                        "webrtc_usage": webrtc_usage,
                        "has_webrtc": has_webrtc,
                        "confidence": confidence,
                        "evidence": evidence,
                        "reasoning": reasoning
                    }
                }
            else:
                print(f"[!] AI åˆ†æå¤±è´¥")
                result = {
                    "rank": rank,
                    "domain": domain,
                    "line": current_line,
                    "timestamp": datetime.now().isoformat(),
                    "status": "ai_failed",
                    "page_info": {
                        "url": elements_data["url"],
                        "status_code": elements_data["status_code"],
                        "content_type": elements_data["content_type"],
                        "title": elements_data["title"],
                        "content_length": elements_data["content_length"],
                        "content_preview": elements_data.get("content_preview", "")
                    },
                    "error": "AI åˆ†æå¤±è´¥"
                }
            
            results.append(result)
            save_progress(current_line, results)
            
            # å»¶è¿Ÿ
            if i < len(domains):
                time.sleep(args.delay)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        save_progress(start_line + len(domains) if start_line else len(domains), results)
    
    # åŠ è½½æœ€ç»ˆç»“æœç”¨äºç»Ÿè®¡
    results = load_results()
    
    # ç»Ÿè®¡ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š æ‰«æå®Œæˆç»Ÿè®¡")
    print("="*60)
    total = len(results)
    success = sum(1 for r in results if r.get("status") == "success")
    failed = sum(1 for r in results if r.get("status") == "failed")
    ai_failed = sum(1 for r in results if r.get("status") == "ai_failed")
    has_webrtc = sum(1 for r in results 
                    if r.get("status") == "success" 
                    and r.get("ai_analysis", {}).get("has_webrtc") is True)
    
    # ç»Ÿè®¡æ–°æ ¼å¼çš„ä½¿ç”¨æƒ…å†µ
    definitely_uses = sum(1 for r in results 
                         if r.get("status") == "success"
                         and r.get("ai_analysis", {}).get("webrtc_usage") == "ç¡®å®šä½¿ç”¨")
    possibly_uses = sum(1 for r in results 
                       if r.get("status") == "success"
                       and r.get("ai_analysis", {}).get("webrtc_usage") == "å¯èƒ½ä½¿ç”¨")
    
    print(f"æ€»è®¡: {total}")
    print(f"æˆåŠŸ: {success}")
    print(f"å¤±è´¥: {failed}")
    print(f"AI åˆ†æå¤±è´¥: {ai_failed}")
    print(f"åŒ…å« WebRTC: {has_webrtc}")
    print(f"  ç¡®å®šä½¿ç”¨: {definitely_uses}")
    print(f"  å¯èƒ½ä½¿ç”¨: {possibly_uses}")
    
    # æ˜¾ç¤ºæ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶ä¿¡æ¯
    print(f"\nç»“æœæ–‡ä»¶:")
    batch_num = 1
    total_batches = 0
    while True:
        batch_file = get_results_file_path(batch_num)
        if os.path.exists(batch_file):
            try:
                with open(batch_file, 'r', encoding='utf-8') as f:
                    batch_results = json.load(f)
                    print(f"  æ‰¹æ¬¡ {batch_num}: {batch_file} ({len(batch_results)} ä¸ªç»“æœ)")
                    total_batches += 1
            except:
                pass
            batch_num += 1
        else:
            break
    
    if total_batches == 0:
        print(f"  æ— ç»“æœæ–‡ä»¶")
    else:
        print(f"\nå…± {total_batches} ä¸ªæ‰¹æ¬¡æ–‡ä»¶")


if __name__ == "__main__":
    # ç¦ç”¨ SSL è­¦å‘Š
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    main()

